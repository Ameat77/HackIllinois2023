{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 21:02:53.876492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import urllib\n",
    "import itertools\n",
    "import random, os, glob\n",
    "from imutils import paths\n",
    "from sklearn.utils import shuffle\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    "waste_labels = {\"Keyboard\":0, \"Mouse\":1, \"Computers\":2}\n",
    "dir_path = \"./Electronics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "  x = []\n",
    "  labels = []\n",
    "  image_paths = sorted(list(paths.list_images(path)))\n",
    "  for image_path in image_paths:\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    x.append(img)\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "    labels.append(waste_labels[label])\n",
    "  x, labels = shuffle(x, labels, random_state=42)\n",
    "  input_shape = (np.array(x[0]).shape[1], np.array(x[0]).shape[1], 3)\n",
    "  print(\"X shape: \", np.array(x).shape)\n",
    "  print(f\"Number of Labels: {len(np.unique(labels))} , Number of Observation: {len(labels)}\")\n",
    "  print(\"Input Shape: \", input_shape)\n",
    "  return x, labels, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (115, 224, 224, 3)\n",
      "Number of Labels: 3 , Number of Observation: 115\n",
      "Input Shape:  (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x, labels, input_shape = load_dataset(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 21:17:34.848854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (224, 224, 3)) ,\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
    "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
    "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
    "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
    "    tf.keras.layers.Dense(3,activation = \"softmax\")   #Adding the Output Layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 550)               10138150  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 550)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               220400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               120300    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 603       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,637,093\n",
      "Trainable params: 10,637,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "adam=Adam(lr=0.001)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 images belonging to 3 classes.\n",
      "Found 19 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "bs=30         #Setting batch size\n",
    "train_dir = \"./Electronics/Train\"   #Setting training directory\n",
    "validation_dir = \"./Electronics/Valid\"   #Setting testing directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(224,224))\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 - 6s - loss: 1.2791 - acc: 0.3333 - val_loss: 0.8473 - val_acc: 0.6316 - 6s/epoch - 6s/step\n",
      "Epoch 2/20\n",
      "1/1 - 4s - loss: 0.4794 - acc: 1.0000 - val_loss: 0.8883 - val_acc: 0.6316 - 4s/epoch - 4s/step\n",
      "Epoch 3/20\n",
      "1/1 - 9s - loss: 0.9259 - acc: 0.5333 - val_loss: 0.8916 - val_acc: 0.6316 - 9s/epoch - 9s/step\n",
      "Epoch 4/20\n",
      "1/1 - 4s - loss: 0.7825 - acc: 0.5000 - val_loss: 0.8550 - val_acc: 0.6316 - 4s/epoch - 4s/step\n",
      "Epoch 5/20\n",
      "1/1 - 5s - loss: 0.7725 - acc: 0.8333 - val_loss: 0.7800 - val_acc: 0.6316 - 5s/epoch - 5s/step\n",
      "Epoch 6/20\n",
      "1/1 - 9s - loss: 0.8898 - acc: 0.6333 - val_loss: 0.7281 - val_acc: 0.6316 - 9s/epoch - 9s/step\n",
      "Epoch 7/20\n",
      "1/1 - 4s - loss: 0.7467 - acc: 0.5000 - val_loss: 0.7017 - val_acc: 0.6316 - 4s/epoch - 4s/step\n",
      "Epoch 8/20\n",
      "1/1 - 9s - loss: 0.7735 - acc: 0.7000 - val_loss: 0.6680 - val_acc: 0.6316 - 9s/epoch - 9s/step\n",
      "Epoch 9/20\n",
      "1/1 - 4s - loss: 0.3062 - acc: 0.8333 - val_loss: 0.6665 - val_acc: 0.6316 - 4s/epoch - 4s/step\n",
      "Epoch 10/20\n",
      "1/1 - 8s - loss: 0.4613 - acc: 0.7000 - val_loss: 0.6702 - val_acc: 0.6316 - 8s/epoch - 8s/step\n",
      "Epoch 11/20\n",
      "1/1 - 9s - loss: 0.3971 - acc: 0.7667 - val_loss: 0.6439 - val_acc: 0.6316 - 9s/epoch - 9s/step\n",
      "Epoch 12/20\n",
      "1/1 - 8s - loss: 0.8223 - acc: 0.5667 - val_loss: 0.5793 - val_acc: 0.7368 - 8s/epoch - 8s/step\n",
      "Epoch 13/20\n",
      "1/1 - 5s - loss: 0.5338 - acc: 0.8333 - val_loss: 0.5686 - val_acc: 0.8421 - 5s/epoch - 5s/step\n",
      "Epoch 14/20\n",
      "1/1 - 9s - loss: 0.5816 - acc: 0.7333 - val_loss: 0.5806 - val_acc: 0.8421 - 9s/epoch - 9s/step\n",
      "Epoch 15/20\n",
      "1/1 - 4s - loss: 0.2423 - acc: 1.0000 - val_loss: 0.5392 - val_acc: 0.8421 - 4s/epoch - 4s/step\n",
      "Epoch 16/20\n",
      "1/1 - 4s - loss: 0.7844 - acc: 0.6667 - val_loss: 0.5671 - val_acc: 0.8421 - 4s/epoch - 4s/step\n",
      "Epoch 17/20\n",
      "1/1 - 10s - loss: 0.6122 - acc: 0.7000 - val_loss: 0.5408 - val_acc: 0.8421 - 10s/epoch - 10s/step\n",
      "Epoch 18/20\n",
      "1/1 - 10s - loss: 0.7056 - acc: 0.7000 - val_loss: 0.4891 - val_acc: 0.8421 - 10s/epoch - 10s/step\n",
      "Epoch 19/20\n",
      "1/1 - 9s - loss: 0.5293 - acc: 0.9000 - val_loss: 0.4225 - val_acc: 0.8421 - 9s/epoch - 9s/step\n",
      "Epoch 20/20\n",
      "1/1 - 10s - loss: 0.5299 - acc: 0.7667 - val_loss: 0.4005 - val_acc: 0.8421 - 10s/epoch - 10s/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=50 // bs,\n",
    "                    epochs=20,\n",
    "                    validation_steps=50 // bs,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./electronicmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model_testing(path):\n",
    "  img = image.load_img(path, target_size=(target_size))\n",
    "  img = image.img_to_array(img, dtype=np.uint8)\n",
    "  img = np.array(img)/255.0\n",
    "  p = model.predict(img.reshape(1,224,224,3))\n",
    "  predicted_class = np.argmax(p[0])\n",
    "  return img, p, predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "img, p, predicted_class = CNN_model_testing(\"./rob_computer.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.52045,     0.28231,     0.19723]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

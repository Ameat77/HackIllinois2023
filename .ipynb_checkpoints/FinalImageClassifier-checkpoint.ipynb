{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import urllib\n",
    "import itertools\n",
    "import random, os, glob\n",
    "from imutils import paths\n",
    "from sklearn.utils import shuffle\n",
    "from urllib.request import urlopen\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import csv\n",
    "import fileinput\n",
    "from autocorrect import Speller\n",
    "import webcolors\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model_testing(path, model, dic):\n",
    "  img = image.load_img(path, target_size=(224,224,3))\n",
    "  img = image.img_to_array(img, dtype=np.uint8)\n",
    "  img = np.array(img)/255.0\n",
    "  p = model.predict(img.reshape(1,224,224,3))\n",
    "  predicted_class = np.argmax(p[0])\n",
    "  return img, dic[predicted_class], p[0][predicted_class]\n",
    "\n",
    "def get_average(filepath, oripath):\n",
    "    im = Image.open(filepath) # Can be many different formats.\n",
    "    pix = im.load()\n",
    "    pixel_dic = {}\n",
    "    for i in range(im.size[0]):\n",
    "        for j in range(im.size[1]):\n",
    "            rgba = pix[i, j]\n",
    "            if rgba in pixel_dic:\n",
    "                pixel_dic[rgba].append((i, j))\n",
    "            else:\n",
    "                pixel_dic[rgba] = [(i, j)]\n",
    "    maximum = -1\n",
    "    best_key = \"\"\n",
    "    for key in pixel_dic:\n",
    "        if (maximum == -1):\n",
    "            maximum = len(pixel_dic[key])\n",
    "            best_key = key\n",
    "        else:\n",
    "            if len(pixel_dic[key]) < maximum:\n",
    "                best_key = key\n",
    "    average = [0, 0, 0]\n",
    "    im_glass = Image.open(oripath) # Can be many different formats.\n",
    "    pix_glass = im_glass.load()\n",
    "    for pixel in pixel_dic[best_key]:\n",
    "        a, b, c = pix_glass[pixel[0], pixel[1]]\n",
    "        average[0] += a\n",
    "        average[1] += b\n",
    "        average[2] += c\n",
    "    average[0] = float(average[0] / len(pixel_dic[best_key]))\n",
    "    average[1] = float(average[1] / len(pixel_dic[best_key]))\n",
    "    average[2] = float(average[2] / len(pixel_dic[best_key]))\n",
    "    return average\n",
    "\n",
    "# SEGMENTATION\n",
    "def image_segment(filepath, outpath):\n",
    "    img = cv2.imread(filepath)\n",
    "    b,g,r = cv2.split(img)\n",
    "    rgb_img = cv2.merge([r,g,b])\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    # noise removal\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    #opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "    closing = cv2.morphologyEx(thresh,cv2.MORPH_CLOSE,kernel, iterations = 2)\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(closing,kernel,iterations=3)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(sure_bg,cv2.DIST_L2,3)\n",
    "    # Threshold\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.1*dist_transform.max(),255,0)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    markers = cv2.watershed(img,markers)\n",
    "    img[markers == -1] = [255,0,0]\n",
    "    #plt.subplot(211),plt.imshow(rgb_img)\n",
    "    plt.imsave(outpath,thresh)\n",
    "    return get_average(outpath, filepath)\n",
    "    \n",
    "def determine_color(r, g, b):\n",
    "    white = [145, 138, 126]\n",
    "    brown = [73, 56, 50]\n",
    "    green = [75, 108, 73]\n",
    "    white_dis = pow(white[0] - r, 2) + pow(white[1] - g, 2) + pow(white[2] - b, 2)\n",
    "    brown_dis = pow(brown[0] - r, 2) + pow(brown[1] - g, 2) + pow(brown[2] - b, 2)\n",
    "    green_dis = pow(green[0] - r, 2) + pow(green[1] - g, 2) + pow(green[2] - b, 2)\n",
    "    if (min(white_dis, brown_dis, green_dis) == white_dis):\n",
    "        return \"white\"\n",
    "    if (min(white_dis, brown_dis, green_dis) == green_dis):\n",
    "        return \"green\"\n",
    "    return \"brown\"\n",
    "\n",
    "def find_color(filepath, outpath):\n",
    "    value = image_segment(filepath, outpath)\n",
    "    return determine_color(value[0], value[1], value[2])\n",
    "\n",
    "\n",
    "def what_is_this(filepath):\n",
    "    trash_dic = {0: \"cardboard\", 1: \"glass\", 2: \"metal\", 3: \"paper\", 4: \"plastic\", 5: \"trash\"}\n",
    "    electronic_dic = {0: \"keyboard\", 1: \"mouse\", 2: \"computer\"}\n",
    "    fruit_dic = {0: \"apple\", 1: \"banana\", 2: \"beetroot\", 3: \"bell pepper\", 4: \"cabbage\", 5: \"capsicum\", 6: \"carrot\", 7: \"cauliflower\", 8: \"chilli pepper\", 9: \"corn\", 10: \"cucumber\", 11: \"eggplant\", 12: \"garlic\", 13: \"ginger\", 14: \"grapes\", 15: \"jalepeno\", 16: \"kiwi\", 17: \"lemon\", 18: \"lettuce\", 19: \"mango\", 20: \"onion\", 21: \"orange\", 22: \"paprika\", 23: \"pear\", 24: \"peas\", 25: \"pineapple\", 26: \"pomegranate\", 27: \"potato\", 28: \"raddish\", 29: \"soy beans\", 30: \"spinach\", 31: \"sweetcorn\", 32: \"sweet potato\", 33: \"tomato\", 34: \"turnip\", 35: \"watermelon\"}\n",
    "    #trash_model = load_model('./Models/genericmodel.h5') #uncomment if models need to be reloaded\n",
    "    #fruit_model = load_model('./Models/fruitmodel.h5')\n",
    "    #electronic_model = load_model('./Models/electronicmodel.h5')\n",
    "    img, trash_class, trash_cert = CNN_model_testing(filepath, trash_model, trash_dic)\n",
    "    #print(trash_class, trash_cert)\n",
    "    img, fruit_class, fruit_cert = CNN_model_testing(filepath, fruit_model, fruit_dic)\n",
    "   #print(fruit_class, fruit_cert)\n",
    "    img, electronic_class, electronic_cert = CNN_model_testing(filepath, electronic_model, electronic_dic)\n",
    "    #print(electronic_class, electronic_cert)\n",
    "    if fruit_cert > .9:\n",
    "        return fruit_class\n",
    "    if trash_cert > .9:\n",
    "        if trash_class == \"glass\":\n",
    "            color = find_color(filepath, \"./glassout/output.png\")\n",
    "            return color + \" \" + trash_class\n",
    "        return trash_class\n",
    "    if electronic_cert > .8:\n",
    "        return electronic_class\n",
    "    else:\n",
    "        return \"Not Found\"\n",
    "\n",
    "# finds closest of brown, green, white for parameter color\n",
    "def closest_color(rgb):\n",
    "    r, g, b = rgb\n",
    "    color_diffs = []\n",
    "    for color in COLORS:\n",
    "        cr, cg, cb = color\n",
    "        color_diff = sqrt((r - cr)**2 + (g - cg)**2 + (b - cb)**2)\n",
    "        color_diffs.append((color_diff, color))\n",
    "    return min(color_diffs)[1]\n",
    "\n",
    "# returns closest of brown, green, white glass\n",
    "def ans_color(rgb):\n",
    "    if (rgb == (128, 96, 77)):\n",
    "        return \"brown\"\n",
    "    if (rgb ==  (0, 255, 0)):\n",
    "        return \"green\"\n",
    "    if (rgb == (255, 255, 255)):\n",
    "        return \"white\"    \n",
    "    \n",
    "    \n",
    "    \n",
    "def place_in_bucket(val):\n",
    "    val = val.lower()\n",
    "    if val == \"green glass\":\n",
    "        return val\n",
    "    if val == \"white glass\":\n",
    "        return val\n",
    "    if val == \"brown glass\":\n",
    "        return val\n",
    "    # bool to check if spellcheck functionality is needed\n",
    "    found = False\n",
    "    # create spell check\n",
    "    spell = Speller()\n",
    "\n",
    "    # empty array to store all matching bins\n",
    "    bins = []\n",
    "    bin = \"yes\"\n",
    "\n",
    "    # int rgb codes for brown, green, white for classifying glass\n",
    "    COLORS = (\n",
    "        (128, 96, 77),\n",
    "        (0, 255, 0),\n",
    "        (255, 255, 255)\n",
    "    )\n",
    "    with open('./csvs/final_trash.csv') as file_obj:\n",
    "        # Create reader object by passing the file \n",
    "        reader_obj = csv.reader(file_obj)\n",
    "        # looks through trash.csv and spellchecks input\n",
    "        for row in reader_obj:\n",
    "            for element in row[1:]:\n",
    "                if (val in element):\n",
    "                  found = True\n",
    "        if found is False:\n",
    "           val = spell(val)\n",
    "        file_obj.close()\n",
    "\n",
    "    # opening final_trash.csv again to classify items\n",
    "    with open('./csvs/final_trash.csv') as file_obj:   \n",
    "        reader_obj = csv.reader(file_obj)\n",
    "        # Iterate over each row in the csv file using reader object\n",
    "        # iterate over each element in row and check if value is in element, and if in element, append proper bin color\n",
    "        for row in reader_obj:\n",
    "            for element in row[1:]:\n",
    "                if (val == element):\n",
    "                    return row[0]\n",
    "                elif (val in element):\n",
    "                        bins.append(row[0])\n",
    "    # sorts input into proper bin using our system of priority\n",
    "    # if input is not found, goes to black\n",
    "    if (len(bins) == 0):\n",
    "        return \"black\"\n",
    "    # if input fits in bin and is contaminated with brown (organic material), goes to black\n",
    "    else:\n",
    "        if ('brown' in bins and ('red' in bins or 'glass' in bins or 'yellow' in bins or 'blue' in bins or 'black' in bins)):\n",
    "            bin = \"black\"\n",
    "        elif ('red' in bins):\n",
    "            bin = \"red\"\n",
    "        elif ('glass' in bins):\n",
    "            bin = \"glass\"\n",
    "        elif ('yellow' in bins):\n",
    "            bin = \"yellow\"\n",
    "        elif ('brown' in bins):\n",
    "            bin = \"brown\"\n",
    "        elif ('blue' in bins):\n",
    "            bin = \"blue\"\n",
    "        elif ('black' in bins):\n",
    "            bin = \"black\"\n",
    "    # sorts glass into proper colored glass bin\n",
    "    if (bin == \"glass\"):\n",
    "        return \"white glass\"\n",
    "    else:\n",
    "        return bin\n",
    "\n",
    "def image_to_bucket(filepath):\n",
    "    obj = what_is_this(filepath)\n",
    "    if obj == \"Not Found\":\n",
    "        return \"Prompt User\"\n",
    "    else:\n",
    "        return place_in_bucket(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle Datasets Used:\n",
    "# Trash: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification\n",
    "# Fruit: https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition\n",
    "# Electronic: https://www.kaggle.com/datasets/dataclusterlabs/electronics-mouse-keyboard-image-dataset + my own dataset found through google images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 01:36:36.209298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Loading our three models!!!\n",
    "trash_model = load_model('./Models/genericmodel.h5')\n",
    "fruit_model = load_model('./Models/fruitmodel.h5')\n",
    "electronic_model = load_model('./Models/electronicmodel.h5')\n",
    "\n",
    "trash_dic = {0: \"cardboard\", 1: \"glass\", 2: \"metal\", 3: \"paper\", 4: \"plastic\", 5: \"trash\"}\n",
    "electronic_dic = {0: \"keyboard\", 1: \"mouse\", 2: \"computer\"}\n",
    "fruit_dic = {0: \"apple\", 1: \"banana\", 2: \"beetroot\", 3: \"bell pepper\", 4: \"cabbage\", 5: \"capsicum\", 6: \"carrot\", 7: \"cauliflower\", 8: \"chilli pepper\", 9: \"corn\", 10: \"cucumber\", 11: \"eggplant\", 12: \"garlic\", 13: \"ginger\", 14: \"grapes\", 15: \"jalepeno\", 16: \"kiwi\", 17: \"lemon\", 18: \"lettuce\", 19: \"mango\", 20: \"onion\", 21: \"orange\", 22: \"paprika\", 23: \"pear\", 24: \"peas\", 25: \"pineapple\", 26: \"pomegranate\", 27: \"potato\", 28: \"raddish\", 29: \"soy beans\", 30: \"spinach\", 31: \"sweetcorn\", 32: \"sweet potato\", 33: \"tomato\", 34: \"turnip\", 35: \"watermelon\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "filepath = \"./TestImages/glass7.jpg\"\n",
    "img, p, predicted_class = CNN_model_testing(filepath, fruit_model, fruit_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "paper 0.9953654\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "lemon 0.98984104\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "mouse 0.9587482\n",
      "black\n"
     ]
    }
   ],
   "source": [
    "print(image_to_bucket(\"./TestImages/lemon.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
